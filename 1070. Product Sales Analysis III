Question:


Table: Sales

+-------------+-------+
| Column Name | Type  |
+-------------+-------+
| sale_id     | int   |
| product_id  | int   |
| year        | int   |
| quantity    | int   |
| price       | int   |
+-------------+-------+
(sale_id, year) is the primary key (combination of columns with unique values) of this table.
product_id is a foreign key (reference column) to Product table.
Each row records a sale of a product in a given year.
A product may have multiple sales entries in the same year.
Note that the per-unit price.

Write a solution to find all sales that occurred in the first year each product was sold.

For each product_id, identify the earliest year it appears in the Sales table.

Return all sales entries for that product in that year.

Return a table with the following columns: product_id, first_year, quantity, and price.
Return the result in any order.

 

Example 1:

Input: 
Sales table:
+---------+------------+------+----------+-------+
| sale_id | product_id | year | quantity | price |
+---------+------------+------+----------+-------+ 
| 1       | 100        | 2008 | 10       | 5000  |
| 2       | 100        | 2009 | 12       | 5000  |
| 7       | 200        | 2011 | 15       | 9000  |
+---------+------------+------+----------+-------+

Output: 
+------------+------------+----------+-------+
| product_id | first_year | quantity | price |
+------------+------------+----------+-------+ 
| 100        | 2008       | 10       | 5000  |
| 200        | 2011       | 15       | 9000  |
+------------+------------+----------+-------+


-----------------------------------------------------------------------------------------------------------------------------------------------



Solution :


from pyspark.sql import SparkSession

# Start Spark session
spark = SparkSession.builder.appName("SalesTable").getOrCreate()

# Data for Sales table
sales_data = [
    (1, 100, 2008, 10, 5000),
    (2, 100, 2009, 12, 5000),
    (7, 200, 2011, 15, 9000)
]

# Columns
sales_columns = ["sale_id", "product_id", "year", "quantity", "price"]

# Create DataFrame
sales_df = spark.createDataFrame(sales_data, sales_columns)

# Show DataFrame
sales_df.show()



from pyspark.sql.functions import col,dense_rank
from pyspark.sql.window import Window

window_spec = Window.partitionBy(col("product_id")).orderBy(col("year"))
sales_df.withColumn("rn", dense_rank().over(window_spec)).filter(col('rn')==1).drop(col("rn")).show()
